{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nimport pickle","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-25T02:37:01.037919Z","iopub.execute_input":"2023-04-25T02:37:01.038459Z","iopub.status.idle":"2023-04-25T02:37:01.045719Z","shell.execute_reply.started":"2023-04-25T02:37:01.038400Z","shell.execute_reply":"2023-04-25T02:37:01.044682Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# For reading previous data\ncsv_data = pd.read_csv('/kaggle/input/nlp-project-v2/Grammer_sentences_v2.csv')\n\nx = csv_data['Input'].to_numpy()\ny = csv_data['Labels'].to_numpy()\n\nx_l = list(x)\ny_l = list(y)","metadata":{"execution":{"iopub.status.busy":"2023-04-25T01:47:44.899156Z","iopub.execute_input":"2023-04-25T01:47:44.900813Z","iopub.status.idle":"2023-04-25T01:50:08.866716Z","shell.execute_reply.started":"2023-04-25T01:47:44.900754Z","shell.execute_reply":"2023-04-25T01:50:08.865580Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"inp_lbl = {'Input': x_l[0:10], 'Labels': y_l[0:10]}\ndf = pd.DataFrame(inp_lbl)\ndf.style","metadata":{"execution":{"iopub.status.busy":"2023-04-25T01:52:20.486632Z","iopub.execute_input":"2023-04-25T01:52:20.487111Z","iopub.status.idle":"2023-04-25T01:52:21.671557Z","shell.execute_reply.started":"2023-04-25T01:52:20.487071Z","shell.execute_reply":"2023-04-25T01:52:21.670137Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"<pandas.io.formats.style.Styler at 0x784716d944d0>","text/html":"<style type=\"text/css\">\n</style>\n<table id=\"T_aa2ca_\">\n  <thead>\n    <tr>\n      <th class=\"blank level0\" >&nbsp;</th>\n      <th class=\"col_heading level0 col0\" >Input</th>\n      <th class=\"col_heading level0 col1\" >Labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th id=\"T_aa2ca_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n      <td id=\"T_aa2ca_row0_col0\" class=\"data row0 col0\" >the effect of widespread dud targets two face up attack position monsters on the field</td>\n      <td id=\"T_aa2ca_row0_col1\" class=\"data row0 col1\" >1. the effect of `` widespread dud '' targets two face up attack position monsters on the field</td>\n    </tr>\n    <tr>\n      <th id=\"T_aa2ca_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n      <td id=\"T_aa2ca_row1_col0\" class=\"data row1 col0\" >tax on sales of stores for non residents are set at 21 for 2014 and 20 in 2015 payable on sales tentatively earned from the difference of the property value some time of purchase price differences according to working time and theyear to which sale couples sales costs based on the approved annual on the base approved by law</td>\n      <td id=\"T_aa2ca_row1_col1\" class=\"data row1 col1\" >capital gains tax on the sale of properties for non-residents is set at 21 for 2014 and 20 in 2015 payable on profits earned on the difference of the property value between the year of purchase purchase price plus costs and the year of sale sales price minus costs based on the approved annual percentage increase on the base value approved by law</td>\n    </tr>\n    <tr>\n      <th id=\"T_aa2ca_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n      <td id=\"T_aa2ca_row2_col0\" class=\"data row2 col0\" >much many brands and sellers still in the market</td>\n      <td id=\"T_aa2ca_row2_col1\" class=\"data row2 col1\" >many brands and sellers still in the market</td>\n    </tr>\n    <tr>\n      <th id=\"T_aa2ca_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n      <td id=\"T_aa2ca_row3_col0\" class=\"data row3 col0\" >this is is the latest maintenance release of samba 3.6</td>\n      <td id=\"T_aa2ca_row3_col1\" class=\"data row3 col1\" >this is is the latest maintenance release of samba 3.6</td>\n    </tr>\n    <tr>\n      <th id=\"T_aa2ca_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n      <td id=\"T_aa2ca_row4_col0\" class=\"data row4 col0\" >fairy or not i 'm the godmother no just look but my outfit for taking the part as godmother</td>\n      <td id=\"T_aa2ca_row4_col1\" class=\"data row4 col1\" >fairy or not i 'm the godmother not just a look but my outfit for taking on the role as godmother</td>\n    </tr>\n    <tr>\n      <th id=\"T_aa2ca_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n      <td id=\"T_aa2ca_row5_col0\" class=\"data row5 col0\" >watcch as this dodge challenger hellcat gets smoked by a tesla model s with the drag strip</td>\n      <td id=\"T_aa2ca_row5_col1\" class=\"data row5 col1\" >watch as this dodge challenger hellcat gets smoked by a tesla model s at the drag strip</td>\n    </tr>\n    <tr>\n      <th id=\"T_aa2ca_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n      <td id=\"T_aa2ca_row6_col0\" class=\"data row6 col0\" >momover these devices have been proven to help consumers during another company his information</td>\n      <td id=\"T_aa2ca_row6_col1\" class=\"data row6 col1\" >moreover these devices are proven to help consumers while another company that information</td>\n    </tr>\n    <tr>\n      <th id=\"T_aa2ca_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n      <td id=\"T_aa2ca_row7_col0\" class=\"data row7 col0\" >ever cloud has a silver lining and it ’ s just possible that we were beaten before the off as the first three home came from stalls eight to 12 while we were drawn in berth two which meant that our fellow was forced to race in the middle the course while the leader kicked on on the stands ’ high rail</td>\n      <td id=\"T_aa2ca_row7_col1\" class=\"data row7 col1\" >every cloud has a silver lining and it ’ s just possible that we were beaten before the off as the first three home came from stalls eight to 12 while we were drawn in berth two which meant that our fellow was forced to race in the middle of the course while the leader kicked on on the stands ’ rail</td>\n    </tr>\n    <tr>\n      <th id=\"T_aa2ca_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n      <td id=\"T_aa2ca_row8_col0\" class=\"data row8 col0\" >worthless involved 's supporting for the movement</td>\n      <td id=\"T_aa2ca_row8_col1\" class=\"data row8 col1\" >get involved and help the movement</td>\n    </tr>\n    <tr>\n      <th id=\"T_aa2ca_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n      <td id=\"T_aa2ca_row9_col0\" class=\"data row9 col0\" >mark mohler said in a post on instagram that he and fellow diver kimberley jeffries have confirmed the identity of wonka bee specilis deep blue on wednesday</td>\n      <td id=\"T_aa2ca_row9_col1\" class=\"data row9 col1\" >on wednesday diver mark mohler said in a post on instagram he and fellow diver kimberley jeffries confirmed the identity of the shark as deep blue</td>\n    </tr>\n  </tbody>\n</table>\n"},"metadata":{}}]},{"cell_type":"markdown","source":"**This section will Encode sentences using Tokenizer**","metadata":{}},{"cell_type":"code","source":"vocab_size = 10000000\noov_tok = '<OOV>' #  Out of Vocabulary\n\ntokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\ntokenizer.fit_on_texts(x_l)\nword_index = tokenizer.word_index","metadata":{"execution":{"iopub.status.busy":"2023-04-25T01:58:48.431728Z","iopub.execute_input":"2023-04-25T01:58:48.432166Z","iopub.status.idle":"2023-04-25T02:10:43.737859Z","shell.execute_reply.started":"2023-04-25T01:58:48.432121Z","shell.execute_reply":"2023-04-25T02:10:43.736632Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"print(f'Number of words in the tokenizer:\\t{len(tokenizer.word_index)}')","metadata":{"execution":{"iopub.status.busy":"2023-04-25T02:11:14.043199Z","iopub.execute_input":"2023-04-25T02:11:14.044679Z","iopub.status.idle":"2023-04-25T02:11:14.055734Z","shell.execute_reply.started":"2023-04-25T02:11:14.044614Z","shell.execute_reply":"2023-04-25T02:11:14.054271Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Number of words in the tokenizer:\t5855332\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Showing example for encoding and decoding words**","metadata":{}},{"cell_type":"code","source":"tokenizer.texts_to_sequences([x_l[0]])","metadata":{"execution":{"iopub.status.busy":"2023-04-25T02:11:17.021952Z","iopub.execute_input":"2023-04-25T02:11:17.022815Z","iopub.status.idle":"2023-04-25T02:11:17.030574Z","shell.execute_reply.started":"2023-04-25T02:11:17.022773Z","shell.execute_reply":"2023-04-25T02:11:17.029432Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"[[2, 977, 4, 7555, 48897, 4087, 95, 688, 51, 1669, 792, 9970, 11, 2, 521]]"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer.sequences_to_texts([[2, 977, 4, 7555, 48897, 4087, 95, 688, 51, 1669, 792, 9970, 11, 2, 521]])","metadata":{"execution":{"iopub.status.busy":"2023-04-25T02:11:19.394697Z","iopub.execute_input":"2023-04-25T02:11:19.395123Z","iopub.status.idle":"2023-04-25T02:11:19.404823Z","shell.execute_reply.started":"2023-04-25T02:11:19.395086Z","shell.execute_reply":"2023-04-25T02:11:19.403728Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"['the effect of widespread dud targets two face up attack position monsters on the field']"},"metadata":{}}]},{"cell_type":"markdown","source":"**Encoding all corpus**","metadata":{}},{"cell_type":"code","source":"x_text_vector = tokenizer.texts_to_sequences(x_l)\ny_text_vector = tokenizer.texts_to_sequences(y_l)","metadata":{"execution":{"iopub.status.busy":"2023-04-25T02:11:22.996848Z","iopub.execute_input":"2023-04-25T02:11:22.997285Z","iopub.status.idle":"2023-04-25T02:30:33.167876Z","shell.execute_reply.started":"2023-04-25T02:11:22.997249Z","shell.execute_reply":"2023-04-25T02:30:33.166577Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"len(x_text_vector) , len(y_text_vector)","metadata":{"execution":{"iopub.status.busy":"2023-04-25T02:31:30.323992Z","iopub.execute_input":"2023-04-25T02:31:30.324483Z","iopub.status.idle":"2023-04-25T02:31:30.333622Z","shell.execute_reply.started":"2023-04-25T02:31:30.324444Z","shell.execute_reply":"2023-04-25T02:31:30.332362Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"(18385502, 18385502)"},"metadata":{}}]},{"cell_type":"code","source":"x_text_vector[2], y_text_vector[2]","metadata":{"execution":{"iopub.status.busy":"2023-04-25T02:34:17.632320Z","iopub.execute_input":"2023-04-25T02:34:17.632758Z","iopub.status.idle":"2023-04-25T02:34:17.640320Z","shell.execute_reply.started":"2023-04-25T02:34:17.632722Z","shell.execute_reply":"2023-04-25T02:34:17.639107Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"([143, 114, 2217, 3, 6147, 211, 6, 2, 267],\n [114, 2217, 3, 6147, 211, 6, 2, 267])"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer.sequences_to_texts([x_text_vector[2], y_text_vector[2]])","metadata":{"execution":{"iopub.status.busy":"2023-04-25T02:34:54.613468Z","iopub.execute_input":"2023-04-25T02:34:54.613887Z","iopub.status.idle":"2023-04-25T02:34:54.622394Z","shell.execute_reply.started":"2023-04-25T02:34:54.613852Z","shell.execute_reply":"2023-04-25T02:34:54.621158Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"['much many brands and sellers still in the market',\n 'many brands and sellers still in the market']"},"metadata":{}}]},{"cell_type":"code","source":"# Saving the tokenizer\nwith open('grammar_tokenizer.pickle', 'wb') as handle:\n    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)","metadata":{"execution":{"iopub.status.busy":"2023-04-25T02:37:05.836804Z","iopub.execute_input":"2023-04-25T02:37:05.837230Z","iopub.status.idle":"2023-04-25T02:37:17.484905Z","shell.execute_reply.started":"2023-04-25T02:37:05.837191Z","shell.execute_reply":"2023-04-25T02:37:17.483252Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}